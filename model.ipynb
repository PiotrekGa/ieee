{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:39:00.114122Z",
     "start_time": "2019-09-02T10:38:57.709157Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from prunedcv import PrunedCV\n",
    "\n",
    "from codes.utils import import_data, drop_columns, cross_val_score_auc, reduce_mem_usage\n",
    "from codes.fe_browser import latest\n",
    "from codes.fe_emails import proton, mappings, labeling\n",
    "from codes.fe_cards import stats\n",
    "from codes.fe_date import dates\n",
    "from codes.fe_relatives import divisions\n",
    "from codes.fe_categorical import pairs, wtf\n",
    "from codes.prepro import prepro\n",
    "from codes.fe_users import users_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:39:00.120156Z",
     "start_time": "2019-09-02T10:39:00.116641Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/'\n",
    "SEARCH_PARAMS = False\n",
    "N_FOLD = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:39:08.685636Z",
     "start_time": "2019-09-02T10:39:00.122537Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train, test, sample_submission = import_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Feature Engineering\n",
    "\n",
    "drop columns, count encoding, aggregation, fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:41:22.551609Z",
     "start_time": "2019-09-02T10:39:08.689259Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/data/python3/ieee/codes/fe_users.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_data = pd.concat([train, test])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 features are going to be dropped for being useless\n",
      "Mem. usage decreased to 1003.32 Mb (12.2% reduction)\n",
      "Mem. usage decreased to 845.63 Mb (12.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train, test = users_stats(train, test)\n",
    "\n",
    "train, test = drop_columns(train, test)\n",
    "\n",
    "train, test = latest(train, test)\n",
    "\n",
    "train, test = proton(train, test)\n",
    "\n",
    "train['nulls1'] = train.isna().sum(axis=1)\n",
    "test['nulls1'] = test.isna().sum(axis=1)\n",
    "\n",
    "train, test = mappings(train, test)\n",
    "train, test = labeling(train, test)\n",
    "\n",
    "train, test = stats(train, test)\n",
    "\n",
    "train, test = divisions(train, test)\n",
    "\n",
    "train, test = dates(train, test)\n",
    "\n",
    "train, test = pairs(train, test)\n",
    "train, test = wtf(train, test)\n",
    "\n",
    "y_train = train['isFraud'].copy()\n",
    "\n",
    "\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "#fill in mean for floats\n",
    "X_train, X_test = prepro(X_train, X_test)\n",
    "\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:41:22.557868Z",
     "start_time": "2019-09-02T10:41:22.553951Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(metric='auc',\n",
    "                       n_estimators=2000,\n",
    "                       boosting_type='gbdt',\n",
    "                       is_unbalance=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:41:22.567551Z",
     "start_time": "2019-09-02T10:41:22.560561Z"
    }
   },
   "outputs": [],
   "source": [
    "prun = PrunedCV(N_FOLD, 0.02, minimize=False)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    joblib.dump(study, 'study.pkl') \n",
    "    \n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 5000), \n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 1000, 3000000), \n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 2, 100000), \n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.00000000001, 10.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.0001, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.000001, 10.0)  \n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.set_params(**params)\n",
    "\n",
    "    return prun.cross_val_score(model, \n",
    "                                X_train, \n",
    "                                y, \n",
    "                                metric='auc', \n",
    "                                shuffle=True, \n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:41:22.575467Z",
     "start_time": "2019-09-02T10:41:22.569931Z"
    }
   },
   "outputs": [],
   "source": [
    "if SEARCH_PARAMS:\n",
    "    if os.path.isfile('study.pkl'):\n",
    "        study = joblib.load('study.pkl')\n",
    "    else:\n",
    "        study = optuna.create_study()\n",
    "\n",
    "    study.optimize(objective, timeout=60*60*7)\n",
    "    joblib.dump(study, 'study.pkl')\n",
    "    best_params = study.best_params\n",
    "    \n",
    "else:\n",
    "    \n",
    "    best_params = {'num_leaves': 302,\n",
    "                   'max_depth': 157,\n",
    "                   'n_estimators': 1200,\n",
    "                   'subsample_for_bin': 290858,\n",
    "                   'min_child_samples': 79,\n",
    "                   'reg_alpha': 1.0919573524807885,\n",
    "                   'colsample_bytree': 0.5653288564015742,\n",
    "                   'learning_rate': 0.028565794309535042}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:41:22.587566Z",
     "start_time": "2019-09-02T10:41:22.577689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 2000,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'metric': 'auc',\n",
       " 'is_unbalance': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:48:00.482212Z",
     "start_time": "2019-09-02T10:41:22.590056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0dddee1d5e47238b6e2743e3df77b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-55b5f40a14bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     submission=sample_submission)\n\u001b[0m",
      "\u001b[0;32m~/data/python3/ieee/codes/utils.py\u001b[0m in \u001b[0;36mcross_val_score_auc\u001b[0;34m(model, X_train, y_train, n_fold, stratify, shuffle, random_state, predict, X_test, submission, verbose)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0my_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mtrain_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(metric='auc',\n",
    "                       n_estimators=2000,\n",
    "                       boosting_type='gbdt',\n",
    "                       is_unbalance=True,)\n",
    "\n",
    "model.set_params(**best_params)\n",
    "\n",
    "cross_val_score_auc(model,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    n_fold=N_FOLD,\n",
    "                    stratify=True,\n",
    "                    shuffle=True,\n",
    "                    random_state=42,\n",
    "                    predict=True,\n",
    "                    X_test=X_test,\n",
    "                    submission=sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:48:00.484666Z",
     "start_time": "2019-09-02T10:38:57.748Z"
    }
   },
   "outputs": [],
   "source": [
    "# ROC accuracy: 0.9751335550235447, Train: 0.9999994424014916\n",
    "# ROC accuracy: 0.979350658169819, Train: 0.9999995681855991\n",
    "# ROC accuracy: 0.978078995160897, Train: 0.9999994764541557\n",
    "# ROC accuracy: 0.9785157994968532, Train: 0.9999991995960142\n",
    "# ROC accuracy: 0.9763520549904333, Train: 0.999999053180651\n",
    "# ROC accuracy: 0.9769807209581446, Train: 0.9999992919944019\n",
    "# ROC accuracy: 0.977527478618695, Train: 0.9999993639818112\n",
    "# ROC accuracy: 0.9786526157982463, Train: 0.9999991182307375\n",
    "\n",
    "# 0.9775739847770791"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
