{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:21:58.438952Z",
     "start_time": "2019-08-16T12:21:58.436520Z"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -r ieee\n",
    "# !rm -r codes\n",
    "# !git clone https://github.com/PiotrekGa/ieee.git\n",
    "# !mv ieee/codes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:22:00.104561Z",
     "start_time": "2019-08-16T12:21:58.441517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from codes import utils\n",
    "from codes import fe_browser\n",
    "from codes import fe_emails\n",
    "from codes import fe_cards\n",
    "from codes import fe_date\n",
    "from codes import fe_relatives\n",
    "from codes import fe_categorical\n",
    "from codes import prepro\n",
    "from codes import fe_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:22:00.109018Z",
     "start_time": "2019-08-16T12:22:00.106247Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/'\n",
    "SEARCH_PARAMS = False\n",
    "n_fold = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:22.206342Z",
     "start_time": "2019-08-16T12:22:00.111378Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "hashing finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/data/python3/ieee/codes/fe_users.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_data = pd.concat([train, test])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat data finished\n",
      "grouping finished\n",
      "stats calculated\n",
      "merged all data\n",
      "50 features are going to be dropped for being useless\n"
     ]
    }
   ],
   "source": [
    "train, test, sample_submission = utils.import_data(DATA_PATH)\n",
    "\n",
    "### Some Feature Engineering\n",
    "train, test = fe_users.users_stats(train, test)\n",
    "\n",
    "train, test = utils.drop_columns(train, test)\n",
    "\n",
    "train, test = fe_browser.latest(train, test)\n",
    "\n",
    "train, test = fe_emails.proton(train, test)\n",
    "\n",
    "train['nulls1'] = train.isna().sum(axis=1)\n",
    "test['nulls1'] = test.isna().sum(axis=1)\n",
    "\n",
    "train, test = fe_emails.mappings(train, test)\n",
    "train, test = fe_emails.labeling(train, test)\n",
    "\n",
    "train, test = fe_cards.stats(train, test)\n",
    "\n",
    "train, test = fe_relatives.divisions(train, test)\n",
    "\n",
    "train, test = fe_date.dates(train, test)\n",
    "\n",
    "train, test = fe_categorical.pairs(train, test)\n",
    "train, test = fe_categorical.wtf(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:22.219725Z",
     "start_time": "2019-08-16T12:23:22.208212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float16    325\n",
       "float64     39\n",
       "float32     39\n",
       "int64       26\n",
       "bool         2\n",
       "int8         1\n",
       "int16        1\n",
       "int32        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:31.710174Z",
     "start_time": "2019-08-16T12:23:22.221909Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "#fill in mean for floats\n",
    "X_train, X_test = prepro.prepro(X_train, X_test)\n",
    "\n",
    "y_train = X_train['isFraud'].copy()\n",
    "X_train = X_train.drop('isFraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:38.478584Z",
     "start_time": "2019-08-16T12:23:31.711848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 561.49 Mb (25.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "X_train = utils.reduce_mem_usage(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:38.485910Z",
     "start_time": "2019-08-16T12:23:38.480852Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['isFraud'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:38.492850Z",
     "start_time": "2019-08-16T12:23:38.489378Z"
    }
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:38.502862Z",
     "start_time": "2019-08-16T12:23:38.495802Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_val_score2(model, X_train, y_train, n_fold):\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True)\n",
    "    \n",
    "    model_scores = []\n",
    "    for train_index, valid_index in folds.split(X_train, y_train):\n",
    "        X_train_, X_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_train_, y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "        model.fit(X_train_,y_train_)\n",
    "        del X_train_,y_train_\n",
    "        val = model.predict_proba(X_valid)[:,1]\n",
    "        del X_valid\n",
    "        model_scores.append(roc_auc_score(y_valid, val))\n",
    "        print('ROC accuracy: {}'.format(model_scores[-1]))\n",
    "        del val, y_valid\n",
    "    \n",
    "    print('')\n",
    "    return np.mean(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T12:23:38.512069Z",
     "start_time": "2019-08-16T12:23:38.505218Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    joblib.dump(study, 'study.pkl')\n",
    "    \n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X_train, y_train, stratify=y_train)\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train_, label=y_train_)\n",
    "    dtest = lgb.Dataset(X_test_, label=y_test_)\n",
    "\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_error',\n",
    "        'verbosity': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300), \n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 2000), \n",
    "        'n_estimators': 1200,\n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 1000, 500000), \n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 2, 200), \n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.00001, 10.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.0001, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.000001, 10.0)   \n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'binary_error')\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dtest], verbose_eval=False, callbacks=[pruning_callback])\n",
    "\n",
    "    preds = gbm.predict(X_test_)\n",
    "    \n",
    "    del X_train_, X_test_, y_train_\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return - roc_auc_score(y_test_, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T13:55:51.355165Z",
     "start_time": "2019-08-16T13:55:51.344515Z"
    }
   },
   "outputs": [],
   "source": [
    "if SEARCH_PARAMS:\n",
    "    study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10))\n",
    "    study.optimize(objective, timeout=60*60*6)\n",
    "\n",
    "    joblib.dump(study, 'study.pkl')\n",
    "\n",
    "    trials_df = pd.DataFrame([trial.value, trial.params] for trial in study.trials)\n",
    "    trials_df.columns = ['value', 'params']\n",
    "    trials_df.sort_values(by='value', inplace=True)\n",
    "    params_for_cv = 10\n",
    "    trials_df = trials_df.iloc[:params_for_cv,:]\n",
    "\n",
    "    model = lgb.LGBMClassifier(metric='auc')\n",
    "\n",
    "    best_params = None\n",
    "    best_value = 0\n",
    "\n",
    "    for params in trials_df.params:\n",
    "        model.set_params(**params)\n",
    "        score = cross_val_score2(model, X_train, y_train, n_fold)\n",
    "\n",
    "        if score > best_value:\n",
    "            best_value = score\n",
    "            best_params = params\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "else:\n",
    "    best_params = {'num_leaves': 302,\n",
    "                   'max_depth': 157,\n",
    "                   'n_estimators': 1200,\n",
    "                   'subsample_for_bin': 290858,\n",
    "                   'min_child_samples': 79,\n",
    "                   'reg_alpha': 1.2,\n",
    "                   'colsample_bytree': 0.5653288564015742,\n",
    "                   'learning_rate': 0.028565794309535042}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T13:56:00.595876Z",
     "start_time": "2019-08-16T13:56:00.593309Z"
    }
   },
   "outputs": [],
   "source": [
    "#benchmark: 0.93493\n",
    "#current:   0.93580\n",
    "\n",
    "# ROC accuracy: 0.9764910549866562, ROC train: 0.9999997134917551\n",
    "# ROC accuracy: 0.9798173483745285, ROC train: 0.9999993176156706\n",
    "# ROC accuracy: 0.9796044896846606, ROC train: 0.999999333921018\n",
    "# ROC accuracy: 0.9799376146756081, ROC train: 0.9999992214473981\n",
    "# ROC accuracy: 0.9779143538610231, ROC train: 0.9999995176057465\n",
    "# ROC accuracy: 0.97729511666745, ROC train: 0.9999993471218942\n",
    "# ROC accuracy: 0.9787953822526927, ROC train: 0.9999992397508431\n",
    "# ROC accuracy: 0.9787187238393698, ROC train: 0.9999991877740493\n",
    "\n",
    "# 0.97857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-16T13:56:03.328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d6a5a9339a4668b9e0acbbc15f98da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC accuracy: 0.9756747397914473, ROC train: 0.9999990467472487\n",
      "ROC accuracy: 0.9798611364168169, ROC train: 0.9999993158409389\n",
      "ROC accuracy: 0.9785223103662416, ROC train: 0.9999988926783552\n",
      "ROC accuracy: 0.9794739842534244, ROC train: 0.9999987835323569\n",
      "ROC accuracy: 0.9777603266912955, ROC train: 0.9999994711299607\n",
      "ROC accuracy: 0.977501842389944, ROC train: 0.9999986431094343\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "model = lgb.LGBMClassifier(metric='auc')\n",
    "model.set_params(**best_params)\n",
    "\n",
    "model_scores = []\n",
    "model_scores_tr = []\n",
    "for train_index, valid_index in tqdm_notebook(folds.split(X_train, y_train), total=n_fold):\n",
    "    \n",
    "    X_train_, X_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_, y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    model.fit(X_train_,y_train_)\n",
    "    train_val = model.predict_proba(X_train_)[:,1]\n",
    "    model_scores_tr.append(roc_auc_score(y_train_, train_val))\n",
    "    del X_train_,y_train_, train_val\n",
    "    pred = model.predict_proba(X_test)[:,1]\n",
    "    val = model.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    del X_valid\n",
    "    model_scores.append(roc_auc_score(y_valid, val))\n",
    "    print('ROC accuracy: {}, ROC train: {}'.format(model_scores[-1], model_scores_tr[-1]))\n",
    "    del val, y_valid\n",
    "    submission['isFraud'] = submission['isFraud'] + pred / n_fold\n",
    "    del pred\n",
    "    gc.collect()\n",
    "    \n",
    "model_score = np.round(np.mean(model_scores),5)\n",
    "print(model_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-16T13:56:05.349Z"
    }
   },
   "outputs": [],
   "source": [
    "timestamp = str(int(datetime.timestamp(datetime.now())))\n",
    "submission.to_csv('{}_submission_{}.csv'.format(timestamp, str(model_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
