{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:00:45.243812Z",
     "start_time": "2019-09-02T08:00:43.937473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from prunedcv import PrunedCV\n",
    "\n",
    "from codes.utils import import_data, drop_columns, cross_val_score_auc\n",
    "from codes.fe_browser import latest\n",
    "from codes.fe_emails import proton, mappings, labeling\n",
    "from codes.fe_cards import stats\n",
    "from codes.fe_date import dates\n",
    "from codes.fe_relatives import divisions\n",
    "from codes.fe_categorical import pairs, wtf\n",
    "from codes.prepro import prepro\n",
    "from codes.fe_users import users_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:00:45.248925Z",
     "start_time": "2019-09-02T08:00:45.246058Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/'\n",
    "SEARCH_PARAMS = False\n",
    "N_FOLD = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:07:21.427951Z",
     "start_time": "2019-09-02T08:00:45.251822Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: (590540, 433)\n",
      "test set shape: (506691, 432)\n",
      "Mem. usage decreased to 1069.77 Mb (45.8% reduction)\n",
      "Mem. usage decreased to 918.79 Mb (45.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "train, test, sample_submission = import_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Feature Engineering\n",
    "\n",
    "drop columns, count encoding, aggregation, fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:09:13.521690Z",
     "start_time": "2019-09-02T08:07:21.429807Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/data/python3/ieee/codes/fe_users.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_data = pd.concat([train, test])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 features are going to be dropped for being useless\n"
     ]
    }
   ],
   "source": [
    "train, test = users_stats(train, test)\n",
    "\n",
    "train, test = drop_columns(train, test)\n",
    "\n",
    "train, test = latest(train, test)\n",
    "\n",
    "train, test = proton(train, test)\n",
    "\n",
    "train['nulls1'] = train.isna().sum(axis=1)\n",
    "test['nulls1'] = test.isna().sum(axis=1)\n",
    "\n",
    "train, test = mappings(train, test)\n",
    "train, test = labeling(train, test)\n",
    "\n",
    "train, test = stats(train, test)\n",
    "\n",
    "train, test = divisions(train, test)\n",
    "\n",
    "train, test = dates(train, test)\n",
    "\n",
    "train, test = pairs(train, test)\n",
    "train, test = wtf(train, test)\n",
    "\n",
    "y_train = train['isFraud'].copy()\n",
    "\n",
    "\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "#fill in mean for floats\n",
    "X_train, X_test = prepro(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:09:13.526888Z",
     "start_time": "2019-09-02T08:09:13.523749Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(metric='auc',\n",
    "                       n_estimators=2000,\n",
    "                       boosting_type='gbdt',\n",
    "                       is_unbalance=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:25:53.732377Z",
     "start_time": "2019-09-02T08:25:53.725570Z"
    }
   },
   "outputs": [],
   "source": [
    "prun = PrunedCV(N_FOLD, 0.02, minimize=False)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    joblib.dump(study, 'study.pkl') \n",
    "    \n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 5000), \n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 1000, 3000000), \n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 2, 100000), \n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.00000000001, 10.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.0001, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.000001, 10.0)  \n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.set_params(**params)\n",
    "\n",
    "    return prun.cross_val_score(model, \n",
    "                                X_train, \n",
    "                                y, \n",
    "                                metric='auc', \n",
    "                                shuffle=True, \n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:25:54.708579Z",
     "start_time": "2019-09-02T08:25:54.702929Z"
    }
   },
   "outputs": [],
   "source": [
    "if SEARCH_PARAMS:\n",
    "    if os.path.isfile('study.pkl'):\n",
    "        study = joblib.load('study.pkl')\n",
    "    else:\n",
    "        study = optuna.create_study()\n",
    "\n",
    "    study.optimize(objective, timeout=60*60*7)\n",
    "    joblib.dump(study, 'study.pkl')\n",
    "    best_params = study.best_params\n",
    "    \n",
    "else:\n",
    "    \n",
    "    best_params = {'num_leaves': 302,\n",
    "                   'max_depth': 157,\n",
    "                   'n_estimators': 1200,\n",
    "                   'subsample_for_bin': 290858,\n",
    "                   'min_child_samples': 79,\n",
    "                   'reg_alpha': 1.0919573524807885,\n",
    "                   'colsample_bytree': 0.5653288564015742,\n",
    "                   'learning_rate': 0.028565794309535042}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T08:26:04.557Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(metric='auc',\n",
    "                       n_estimators=2000,\n",
    "                       boosting_type='gbdt',\n",
    "                       is_unbalance=True,)\n",
    "\n",
    "model.set_params(**best_params)\n",
    "\n",
    "cross_val_score_auc(model,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    n_fold=N_FOLD,\n",
    "                    shuffle=False,\n",
    "                    random_state=42,\n",
    "                    predict=True,\n",
    "                    X_test=X_test,\n",
    "                    submission=sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
