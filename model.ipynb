{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:24:44.493904Z",
     "start_time": "2019-08-15T20:24:44.488820Z"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -r ieee\n",
    "# !rm -r codes\n",
    "# !git clone https://github.com/PiotrekGa/ieee.git\n",
    "# !mv ieee/codes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:24:48.783712Z",
     "start_time": "2019-08-15T20:24:44.500461Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 22:24:48.751556 4649416128 deprecation_wrapper.py:119] From /Users/piotrgabrys/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/optuna/integration/tensorflow.py:7: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from codes import utils\n",
    "from codes import fe_browser\n",
    "from codes import fe_emails\n",
    "from codes import fe_cards\n",
    "from codes import fe_date\n",
    "from codes import fe_relatives\n",
    "from codes import fe_categorical\n",
    "from codes import prepro\n",
    "from codes import fe_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:24:48.824329Z",
     "start_time": "2019-08-15T20:24:48.801162Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/'\n",
    "SEARCH_PARAMS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:26:44.765665Z",
     "start_time": "2019-08-15T20:24:48.844406Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "hashing finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/data/python3/ieee/codes/fe_users.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_data = pd.concat([train, test])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat data finished\n",
      "grouping finished\n",
      "stats calculated\n",
      "merged all data\n",
      "50 features are going to be dropped for being useless\n"
     ]
    }
   ],
   "source": [
    "train, test, sample_submission = utils.import_data(DATA_PATH)\n",
    "\n",
    "### Some Feature Engineering\n",
    "train, test = fe_users.users_stats(train, test)\n",
    "\n",
    "train, test = utils.drop_columns(train, test)\n",
    "\n",
    "train, test = fe_browser.latest(train, test)\n",
    "\n",
    "train, test = fe_emails.proton(train, test)\n",
    "\n",
    "train['nulls1'] = train.isna().sum(axis=1)\n",
    "test['nulls1'] = test.isna().sum(axis=1)\n",
    "\n",
    "train, test = fe_emails.mappings(train, test)\n",
    "train, test = fe_emails.labeling(train, test)\n",
    "\n",
    "train, test = fe_cards.stats(train, test)\n",
    "\n",
    "train, test = fe_relatives.divisions(train, test)\n",
    "\n",
    "train, test = fe_date.dates(train, test)\n",
    "\n",
    "train, test = fe_categorical.pairs(train, test)\n",
    "train, test = fe_categorical.wtf(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:26:44.784863Z",
     "start_time": "2019-08-15T20:26:44.768021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 436)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:26:59.281946Z",
     "start_time": "2019-08-15T20:26:44.794031Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "#fill in mean for floats\n",
    "X_train, X_test = prepro.prepro(X_train, X_test)\n",
    "\n",
    "y_train = X_train['isFraud'].copy()\n",
    "X_train = X_train.drop('isFraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:06.438784Z",
     "start_time": "2019-08-15T20:26:59.283524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 566.00 Mb (26.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "X_train = utils.reduce_mem_usage(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:06.447988Z",
     "start_time": "2019-08-15T20:27:06.441381Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['isFraud'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:15.338952Z",
     "start_time": "2019-08-15T20:27:15.335684Z"
    }
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:07.486847Z",
     "start_time": "2019-08-15T20:24:44.522Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_val_score2(model, X_train, y_train, n_fold):\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True)\n",
    "    \n",
    "    model_scores = []\n",
    "    for train_index, valid_index in folds.split(X_train, y_train):\n",
    "        X_train_, X_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_train_, y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "        model.fit(X_train_,y_train_)\n",
    "        del X_train_,y_train_\n",
    "        val = model.predict_proba(X_valid)[:,1]\n",
    "        del X_valid\n",
    "        model_scores.append(roc_auc_score(y_valid, val))\n",
    "        print('ROC accuracy: {}'.format(model_scores[-1]))\n",
    "        del val, y_valid\n",
    "    \n",
    "    print('')\n",
    "    return np.mean(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:07.488310Z",
     "start_time": "2019-08-15T20:24:44.526Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    joblib.dump(study, 'study.pkl')\n",
    "    \n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X_train, y_train, stratify=y_train)\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train_, label=y_train_)\n",
    "    dtest = lgb.Dataset(X_test_, label=y_test_)\n",
    "\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_error',\n",
    "        'verbosity': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300), \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 2000), \n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 1000, 500000), \n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 2, 200), \n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.00001, 10.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.0001, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.000001, 10.0)   \n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'binary_error')\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dtest], verbose_eval=False, callbacks=[pruning_callback])\n",
    "\n",
    "    preds = gbm.predict(X_test_)\n",
    "    \n",
    "    del X_train_, X_test_, y_train_\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return - roc_auc_score(y_test_, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:07.490021Z",
     "start_time": "2019-08-15T20:24:44.536Z"
    }
   },
   "outputs": [],
   "source": [
    "if SEARCH_PARAMS:\n",
    "    study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=1))\n",
    "    study.optimize(objective, timeout=60*60*6)\n",
    "\n",
    "    joblib.dump(study, 'study.pkl')\n",
    "\n",
    "    trials_df = pd.DataFrame([trial.value, trial.params] for trial in study.trials)\n",
    "    trials_df.columns = ['value', 'params']\n",
    "    trials_df.sort_values(by='value', inplace=True)\n",
    "    params_for_cv = 10\n",
    "    trials_df = trials_df.iloc[:params_for_cv,:]\n",
    "\n",
    "    model = lgb.LGBMClassifier(metric='auc')\n",
    "    n_folds = 8\n",
    "\n",
    "    best_params = None\n",
    "    best_value = 0\n",
    "\n",
    "    for params in trials_df.params:\n",
    "        model.set_params(**params)\n",
    "        score = cross_val_score2(model, X_train, y_train, n_folds)\n",
    "\n",
    "        if score > best_value:\n",
    "            best_value = score\n",
    "            best_params = params\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "else:\n",
    "    best_params = {'num_leaves': 302,\n",
    "                   'max_depth': 157,\n",
    "                   'n_estimators': 1200,\n",
    "                   'subsample_for_bin': 290858,\n",
    "                   'min_child_samples': 79,\n",
    "                   'reg_alpha': 1.0919573524807885,\n",
    "                   'colsample_bytree': 0.5653288564015742,\n",
    "                   'learning_rate': 0.028565794309535042}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:07.491338Z",
     "start_time": "2019-08-15T20:24:44.539Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 8\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "model = lgb.LGBMClassifier(metric='auc')\n",
    "model.set_params(**best_params)\n",
    "\n",
    "model_scores = []\n",
    "model_scores_tr = []\n",
    "for train_index, valid_index in folds.split(X_train, y_train):\n",
    "    \n",
    "    X_train_, X_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_, y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    model.fit(X_train_,y_train_)\n",
    "    train_val = model.predict_proba(X_train_)[:,1]\n",
    "    model_scores_tr.append(roc_auc_score(y_train_, train_val))\n",
    "    del X_train_,y_train_, train_val\n",
    "    pred = model.predict_proba(X_test)[:,1]\n",
    "    val = model.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    del X_valid\n",
    "    model_scores.append(roc_auc_score(y_valid, val))\n",
    "    print('ROC accuracy: {}, ROC train: {}'.format(model_scores[-1], model_scores_tr[-1]))\n",
    "    del val, y_valid\n",
    "    submission['isFraud'] = submission['isFraud'] + pred / n_fold\n",
    "    del pred\n",
    "    gc.collect()\n",
    "    \n",
    "model_score = np.round(np.mean(model_scores),4)\n",
    "print(model_score)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:27:07.492850Z",
     "start_time": "2019-08-15T20:24:44.541Z"
    }
   },
   "outputs": [],
   "source": [
    "timestamp = str(int(datetime.timestamp(datetime.now())))\n",
    "submission.to_csv('{}_submission_{}.csv'.format(timestamp, str(model_score)))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
