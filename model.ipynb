{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:09:05.033115Z",
     "start_time": "2019-09-07T16:09:02.189905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from prunedcv import PrunedCV\n",
    "\n",
    "from codes.utils import import_data, drop_columns, cross_val_score_auc, reduce_mem_usage\n",
    "from codes.fe_browser import latest\n",
    "from codes.fe_emails import proton, mappings, labeling\n",
    "from codes.fe_cards import stats\n",
    "from codes.fe_date import dates\n",
    "from codes.fe_relatives import divisions\n",
    "from codes.fe_categorical import pairs, wtf\n",
    "from codes.prepro import prepro\n",
    "from codes.fe_users import users_stats\n",
    "\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T17:35:32.347537Z",
     "start_time": "2019-09-07T17:35:32.342621Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/'\n",
    "SEARCH_PARAMS = False\n",
    "SEARCH_FEATURES = False\n",
    "N_FOLD = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:09:16.617411Z",
     "start_time": "2019-09-07T16:09:05.040468Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train, test, sample_submission = import_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Feature Engineering\n",
    "\n",
    "drop columns, count encoding, aggregation, fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:13:01.820270Z",
     "start_time": "2019-09-07T16:09:16.620831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgabrys/data/python3/ieee/codes/fe_users.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_data = pd.concat([train, test])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 features are going to be dropped for being useless\n",
      "Mem. usage decreased to 1003.32 Mb (12.2% reduction)\n",
      "Mem. usage decreased to 845.63 Mb (12.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train, test = users_stats(train, test)\n",
    "\n",
    "train, test = drop_columns(train, test)\n",
    "\n",
    "train, test = latest(train, test)\n",
    "\n",
    "train, test = proton(train, test)\n",
    "\n",
    "train['nulls1'] = train.isna().sum(axis=1)\n",
    "test['nulls1'] = test.isna().sum(axis=1)\n",
    "\n",
    "train, test = mappings(train, test)\n",
    "train, test = labeling(train, test)\n",
    "\n",
    "train, test = stats(train, test)\n",
    "\n",
    "train, test = divisions(train, test)\n",
    "\n",
    "train, test = dates(train, test)\n",
    "\n",
    "train, test = pairs(train, test)\n",
    "train, test = wtf(train, test)\n",
    "\n",
    "y_train = train['isFraud'].copy()\n",
    "\n",
    "\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "\n",
    "#fill in mean for floats\n",
    "X_train, X_test = prepro(X_train, X_test)\n",
    "\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:13:34.701324Z",
     "start_time": "2019-09-07T16:13:01.834061Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[X_train == np.inf] = -1\n",
    "X_train[X_train == -np.inf] = -1\n",
    "X_test[X_test == np.inf] = -1\n",
    "X_test[X_test == -np.inf] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:13:35.984286Z",
     "start_time": "2019-09-07T16:13:34.704084Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.drop(['TransactionDT', 'TransactionAmt'], axis=1, inplace=True)\n",
    "X_test.drop(['TransactionDT', 'TransactionAmt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:51:06.109998Z",
     "start_time": "2019-09-07T16:13:35.991205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 231 features.\n"
     ]
    }
   ],
   "source": [
    "if SEARCH_FEATURES:\n",
    "    best_params = {'num_leaves': 302,\n",
    "                 'max_depth': 157,\n",
    "                 'subsample_for_bin': 290858,\n",
    "                 'min_child_samples': 79,\n",
    "                 'reg_alpha': 0.9919573524807885,\n",
    "                 'colsample_bytree': 0.5653288564015742,\n",
    "                 'learning_rate': 0.028565794309535042}\n",
    "    mod = LGBMClassifier(metric='auc',\n",
    "                     boosting_type='gbdt')\n",
    "    mod.set_params(**best_params)\n",
    "    rfe = RFECV(mod, step=25, min_features_to_select=150, cv=4, scoring='roc_auc', verbose=1)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    columns = list(X_test.columns[rfe.get_support()])\n",
    "    joblib.dump(columns, 'columns.pkl')\n",
    "\n",
    "    X_train = X_train.loc[:,columns]\n",
    "    X_test = X_test.loc[:,columns]\n",
    "else:\n",
    "    columns = joblib.load('columns.pkl')\n",
    "    columns.append('TransactionAmt')\n",
    "    X_train = X_train.loc[:,columns]\n",
    "    X_test = X_test.loc[:,columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:51:06.155896Z",
     "start_time": "2019-09-07T16:51:06.138750Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(metric='auc',\n",
    "                       n_estimators=1000,\n",
    "                       boosting_type='gbdt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T15:49:59.510614Z",
     "start_time": "2019-09-07T15:49:36.302Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:51:06.479767Z",
     "start_time": "2019-09-07T16:51:06.159184Z"
    }
   },
   "outputs": [],
   "source": [
    "prun = PrunedCV(N_FOLD, 0.02, minimize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:51:06.511347Z",
     "start_time": "2019-09-07T16:51:06.485115Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    joblib.dump(study, 'study.pkl') \n",
    "    \n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 1500), \n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 1500), \n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 10, 3000000), \n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 2, 100000), \n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.00000000001, 10.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.0001, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.000001, 10.0)  \n",
    "    }\n",
    "    \n",
    "#     params = {\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 300, 310), \n",
    "#         'max_depth': trial.suggest_int('max_depth', 150, 160), \n",
    "#         'subsample_for_bin': trial.suggest_int('subsample_for_bin', 290000, 291000), \n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 75, 82), \n",
    "#         'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.990, 0.993),\n",
    "#         'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.55, 0.58),\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 0.02, 0.03)  \n",
    "#     }\n",
    "    \n",
    "    \n",
    "    model.set_params(**params)\n",
    "\n",
    "    return prun.cross_val_score(model, \n",
    "                                X_train, \n",
    "                                y_train, \n",
    "                                metric='auc', \n",
    "                                shuffle=True, \n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:51:06.535372Z",
     "start_time": "2019-09-07T16:51:06.518516Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if SEARCH_PARAMS:\n",
    "    if os.path.isfile('study.pkl'):\n",
    "        study = joblib.load('study.pkl')\n",
    "    else:\n",
    "        study = optuna.create_study()\n",
    "\n",
    "    study.optimize(objective, timeout=60*60*12)\n",
    "    joblib.dump(study, 'study.pkl')\n",
    "    best_params = study.best_params\n",
    "    \n",
    "else:\n",
    "    \n",
    "    best_params = {'num_leaves': 302,\n",
    "                 'max_depth': 157,\n",
    "                 'subsample_for_bin': 290858,\n",
    "                 'min_child_samples': 79,\n",
    "                 'reg_alpha': 0.9919573524807885,\n",
    "                 'colsample_bytree': 0.5653288564015742,\n",
    "                 'learning_rate': 0.028565794309535042}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T17:25:04.180774Z",
     "start_time": "2019-09-07T16:51:06.542310Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e9bf55ad794337858f53aff36d5cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC accuracy: 0.9747431963385, Train: 0.9999885797125879\n",
      "ROC accuracy: 0.9783240331977164, Train: 0.9999843937860894\n",
      "ROC accuracy: 0.9776021473477676, Train: 0.999985213046599\n",
      "ROC accuracy: 0.9776277016948994, Train: 0.9999816344110959\n",
      "ROC accuracy: 0.9763353593387132, Train: 0.9999850285854255\n",
      "ROC accuracy: 0.975954065269458, Train: 0.9999858101613444\n",
      "ROC accuracy: 0.9777313673449186, Train: 0.9999735340342005\n",
      "ROC accuracy: 0.9765956112785853, Train: 0.99998214722258\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9768641852263198"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(**best_params)\n",
    "\n",
    "cross_val_score_auc(model,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    n_fold=N_FOLD,\n",
    "                    stratify=True,\n",
    "                    shuffle=True,\n",
    "                    random_state=42,\n",
    "                    predict=True,\n",
    "                    X_test=X_test,\n",
    "                    submission=sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T17:25:04.188742Z",
     "start_time": "2019-09-07T17:25:04.183513Z"
    }
   },
   "outputs": [],
   "source": [
    "# ROC accuracy: 0.9747431963385, Train: 0.9999885797125879\n",
    "# ROC accuracy: 0.9783240331977164, Train: 0.9999843937860894\n",
    "# ROC accuracy: 0.9776021473477676, Train: 0.999985213046599\n",
    "# ROC accuracy: 0.9776277016948994, Train: 0.9999816344110959\n",
    "# ROC accuracy: 0.9763353593387132, Train: 0.9999850285854255\n",
    "# ROC accuracy: 0.975954065269458, Train: 0.9999858101613444\n",
    "# ROC accuracy: 0.9777313673449186, Train: 0.9999735340342005\n",
    "# ROC accuracy: 0.9765956112785853, Train: 0.99998214722258\n",
    "\n",
    "\n",
    "# 0.9768641852263198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
